{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'popularity'\n",
    "\n",
    "features =  ['valence',\n",
    " 'acousticness',\n",
    " 'artists',\n",
    " 'danceability',\n",
    " 'duration_ms',\n",
    " 'energy',\n",
    " 'explicit',\n",
    " 'instrumentalness',\n",
    " 'liveness',\n",
    " 'loudness',\n",
    " 'mode',\n",
    " 'speechiness',\n",
    " 'tempo']\n",
    "\n",
    "data_old_path = \"data/old_VS_new/old_era_data.csv\"\n",
    "data_new_path = \"data/old_VS_new/new_era_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_answers(answer, actual):\n",
    "    answer = list(answer)\n",
    "    actual = list(actual)\n",
    "    ok = 0\n",
    "    diff = 15\n",
    "    ans_list = []\n",
    "    for i in range(len(answer)):\n",
    "        if(actual[i] < answer[i]+diff and actual[i] > answer[i]-diff ):\n",
    "            ok+=1\n",
    "            ans_list.append(1)\n",
    "        else:\n",
    "            ans_list.append(0)\n",
    "    return ok/len(answer)\n",
    "\n",
    "def get_accuracy(classifier, test):\n",
    "    X = test[\"x\"]\n",
    "    Y = test[\"y\"]\n",
    "    ans = classifier.predict(X)\n",
    "\n",
    "    return check_answers(ans, Y)\n",
    "    \n",
    "\n",
    "def print_features(classifier):\n",
    "    feature_importances_df = pd.DataFrame(classifier.feature_importances_, columns=['importance'], \n",
    "        index = features).sort_values('importance', ascending=False)\n",
    "\n",
    "    print(feature_importances_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_tree_crit(features, df):\n",
    "    best_options = {\"val\" : 0, \"crit\" : \"gini\", \"depth\" : 10}\n",
    "    for cr in [\"gini\", 'entropy']:\n",
    "        for dp in range(1,15):\n",
    "            myTree = tree.DecisionTreeClassifier(criterion=cr, max_depth=dp)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], \n",
    "                                                    test_size=0.2, random_state=1)\n",
    "\n",
    "            myTree.fit(X_train, y_train)\n",
    "\n",
    "            acc = get_accuracy(myTree, { \"x\" : X_test, \"y\" : y_test })\n",
    "\n",
    "            if acc > best_options[\"val\"] :\n",
    "                best_options[\"val\"] = acc\n",
    "                best_options[\"crit\"] = cr\n",
    "                best_options[\"depth\"] = dp\n",
    "    return best_options\n",
    "            \n",
    "\n",
    "def create_tree(features, path):\n",
    "    df = pd.read_csv(str(path))\n",
    "    best_options = best_tree_crit(features, df)\n",
    "\n",
    "    myTree = tree.DecisionTreeClassifier(criterion=best_options['crit'], max_depth=best_options['depth'])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], \n",
    "                                                    test_size=0.2, random_state=1)\n",
    "\n",
    "    myTree.fit(X_train, y_train)\n",
    "\n",
    "    acc = get_accuracy(myTree, { \"x\" : X_test, \"y\" : y_test })\n",
    "\n",
    "    print(\"ACC: \"+acc, \" Depth: \"+best_options['depth'], \" Criterion: \"+best_options['crit'])\n",
    "\n",
    "    print_features(myTree)\n",
    "\n",
    "create_tree(features, data_old_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-25-f5cb4e4ee0fd>, line 34)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-25-f5cb4e4ee0fd>\"\u001b[1;36m, line \u001b[1;32m34\u001b[0m\n\u001b[1;33m    print(\"ACC: \"+acc, \" Depth: \"+best_options['depth'], \" Criterion: \"best_options['crit'])\u001b[0m\n\u001b[1;37m                                                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def create_boost(features, data_path):\n",
    "    abc = AdaBoostClassifier(n_estimators=50, learning_rate=1)\n",
    "\n",
    "    df = pd.read_csv(str(data_path))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=1)\n",
    "\n",
    "    abc.fit(X_train, y_train)\n",
    "\n",
    "    ans = abc.predict(X_test)\n",
    "    print(\"Accuracy: \", check_answers(ans, y_test, X_test))\n",
    "\n",
    "def create_forest(features, data_path):\n",
    "    dp=9\n",
    "    est=95\n",
    "\n",
    "    df = pd.read_csv(str(data_path))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=1)\n",
    "\n",
    "    print(type(X_test))\n",
    "    forestClassifier = RandomForestClassifier(n_estimators=est, max_depth=dp, random_state=0, criterion=\"gini\") # the best num, crit & depth (decade 10s)\n",
    "    forestRegressor = RandomForestRegressor(n_estimators=est, max_depth=dp, random_state=0) # the best num, crit & depth (decade 10s)\n",
    "\n",
    "    forestClassifier.fit(X_train, y_train)\n",
    "    ansClassifier = forestClassifier.predict(X_test)\n",
    "    forestRegressor.fit(X_train, y_train)\n",
    "    ansRegressor = forestRegressor.predict(X_test)\n",
    "    \n",
    "    print(\"Classifier Num:\", est, \" Depth:\", dp, \" Accuracy: \", check_answers(ansClassifier, y_test, X_test))\n",
    "    \n",
    "\n",
    "    feature_classifier_importances_df = pd.DataFrame(\n",
    "        {\"feature\": features, \"importance\": forestClassifier.feature_importances_}\n",
    "    ).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "    # Display\n",
    "    print(feature_classifier_importances_df)\n",
    "\n",
    "    print(\"Regressor Num:\", est, \" Depth:\", dp, \" Accuracy: \", check_answers(ansRegressor, y_test, X_test))\n",
    "    feature_regressor_importances_df = pd.DataFrame(\n",
    "        {\"feature\": features, \"importance\": forestRegressor.feature_importances_}\n",
    "    ).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "    # Display\n",
    "    print(feature_regressor_importances_df)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "create_forest(feature_2, data_path_2)\n",
    "create_forest(feature, data_path_all)\n",
    "print(\"BOOST\")\n",
    "print(\"feature_2\")\n",
    "#create_boost(feature_2, data_path_2)\n",
    "#create_boost(feature, data_path_all)\n",
    "\n",
    "#create_forest(feature_2, data_path_3)\n",
    "#create_forest(feature_2, data_path_all)\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}