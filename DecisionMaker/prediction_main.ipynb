{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'popularity'\n",
    "\n",
    "features =  ['valence',\n",
    " 'acousticness',\n",
    " 'artists',\n",
    " 'danceability',\n",
    " 'duration_ms',\n",
    " 'energy',\n",
    " 'explicit',\n",
    " 'instrumentalness',\n",
    " 'liveness',\n",
    " 'loudness',\n",
    " 'mode',\n",
    " 'speechiness',\n",
    " 'tempo']\n",
    "\n",
    "data_old_path = \"../data/old_VS_new/old_era_data.csv\"\n",
    "data_new_path = \"../data/old_VS_new/new_era_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_answers(answer, actual):\n",
    "    answer = list(answer)\n",
    "    actual = list(actual)\n",
    "    ok = 0\n",
    "    diff = 15\n",
    "    ans_list = []\n",
    "    for i in range(len(answer)):\n",
    "        if(actual[i] < answer[i]+diff and actual[i] > answer[i]-diff ):\n",
    "            ok+=1\n",
    "            ans_list.append(1)\n",
    "        else:\n",
    "            ans_list.append(0)\n",
    "    return ok/len(answer)\n",
    "\n",
    "def get_accuracy(classifier, test):\n",
    "    X = test[\"x\"]\n",
    "    Y = test[\"y\"]\n",
    "    ans = classifier.predict(X)\n",
    "\n",
    "    return check_answers(ans, Y)\n",
    "    \n",
    "\n",
    "def print_features(classifier):\n",
    "    feature_importances_df = pd.DataFrame(classifier.feature_importances_, columns=['importance'], \n",
    "        index = features).sort_values('importance', ascending=False)\n",
    "\n",
    "    print(feature_importances_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'val': 0.7089767301819433, 'crit': 'gini', 'depth': 7}\n                  importance\nloudness            0.316678\nduration_ms         0.124791\nenergy              0.086880\nartists             0.072809\ninstrumentalness    0.071317\nvalence             0.066864\ndanceability        0.065826\nexplicit            0.064932\nspeechiness         0.039694\nacousticness        0.036959\nliveness            0.036476\ntempo               0.014720\nmode                0.002053\n"
     ]
    }
   ],
   "source": [
    "def best_tree_crit(features, df):\n",
    "    best_options = {\"val\" : 0, \"crit\" : \"gini\", \"depth\" : 10}\n",
    "    for cr in [\"gini\", \"entropy\"] :\n",
    "        for dp in range(3,13):\n",
    "            myTree = tree.DecisionTreeClassifier(criterion=cr, max_depth=dp)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], \n",
    "                                                    test_size=0.2, random_state=1)\n",
    "\n",
    "            myTree.fit(X_train, y_train)\n",
    "\n",
    "            acc = get_accuracy(myTree, { \"x\" : X_test, \"y\" : y_test })\n",
    "\n",
    "            if acc > best_options[\"val\"] :\n",
    "                best_options[\"val\"] = acc\n",
    "                best_options[\"crit\"] = cr\n",
    "                best_options[\"depth\"] = dp\n",
    "    return best_options\n",
    "            \n",
    "\n",
    "def create_tree(features, path):\n",
    "    df = pd.read_csv(str(path))\n",
    "    \n",
    "    #best_options = best_tree_crit(features, df)\n",
    "\n",
    "    best_options = {'val': 0.7090627553873284, 'crit': 'gini', 'depth': 7} #best for new data\n",
    "\n",
    "    myTree = tree.DecisionTreeClassifier(criterion=best_options['crit'], max_depth=best_options['depth'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], \n",
    "                                                    test_size=0.2, random_state=1)\n",
    "\n",
    "    myTree.fit(X_train, y_train)\n",
    "    acc = get_accuracy(myTree, { \"x\" : X_test, \"y\" : y_test })\n",
    "    best_options['val']=acc\n",
    "\n",
    "    print(best_options)\n",
    "    print_features(myTree)\n",
    "\n",
    "create_tree(features, data_new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'val': 0.7041593186803734, 'ests': 149, 'alg': 'SAMME'}\n                  importance\nloudness            0.806097\nexplicit            0.112523\nduration_ms         0.051014\nacousticness        0.030367\nvalence             0.000000\nartists             0.000000\ndanceability        0.000000\nenergy              0.000000\ninstrumentalness    0.000000\nliveness            0.000000\nmode                0.000000\nspeechiness         0.000000\ntempo               0.000000\n"
     ]
    }
   ],
   "source": [
    "def best_ada_crit(features, df):\n",
    "    best_options = {\"val\" : 0, \"ests\" : 10, \"alg\":\"SAMME.R\"}\n",
    "    for al in [\"SAMME\"] :\n",
    "        for es in range(148,155,1):\n",
    "            adb = AdaBoostClassifier(n_estimators=es, algorithm=al)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], \n",
    "                                                    test_size=0.2, random_state=1)\n",
    "\n",
    "            adb.fit(X_train, y_train)\n",
    "\n",
    "            acc = get_accuracy(adb, { \"x\" : X_test, \"y\" : y_test })\n",
    "\n",
    "            if acc > best_options[\"val\"] :\n",
    "                best_options[\"val\"] = acc\n",
    "                best_options[\"ests\"] = es\n",
    "                best_options[\"alg\"] = al\n",
    "            print(\"ACC: \",acc, \" Estimators: \",es, \" Algorithm: \",al)\n",
    "    return best_options\n",
    "\n",
    "def create_ada(features, path):\n",
    "    df = pd.read_csv(str(path))\n",
    "    #best_options = best_ada_crit(features, df)\n",
    "\n",
    "    #best_options = {\"val\" : 0, \"ests\" : 51, \"alg\":\"SAMME.R\"} #best for old data\n",
    "    best_options = {\"val\" : 0.7041593186803734, \"ests\" : 149,  \"alg\":  \"SAMME\"} #best for new data\n",
    "\n",
    "    adb = AdaBoostClassifier(n_estimators=best_options['ests'], algorithm=best_options['alg'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], \n",
    "                                            test_size=0.2, random_state=1)\n",
    "    adb.fit(X_train, y_train)\n",
    "    acc = get_accuracy(adb, { \"x\" : X_test, \"y\" : y_test })\n",
    "    \n",
    "    best_options['val']=acc\n",
    "\n",
    "    print(best_options)\n",
    "    print_features(adb)\n",
    "\n",
    "create_ada(features, data_new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'val': 0.7343971783732633, 'ests': 166, 'crit': 'gini', 'depth': 10}\n                  importance\nloudness            0.146652\nduration_ms         0.102415\ndanceability        0.090231\nvalence             0.086262\nacousticness        0.083579\nenergy              0.082736\nartists             0.081595\ninstrumentalness    0.075973\nspeechiness         0.072249\nliveness            0.071319\ntempo               0.070042\nexplicit            0.028550\nmode                0.008395\n"
     ]
    }
   ],
   "source": [
    "def best_rdf_crit(features, df):\n",
    "    best_options = {\"val\" : 0, \"ests\" : 10, \"crit\":\"gini\", \"depth\":10}\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], \n",
    "                                                        test_size=0.2, random_state=1)\n",
    "\n",
    "    for cr in [\"gini\", \"entropy\"] :\n",
    "        for dp in range(7,15):\n",
    "            for es in range(150,171,2):\n",
    "                rdf = RandomForestClassifier(n_estimators=es, max_depth=dp, criterion=cr)\n",
    "\n",
    "                rdf.fit(X_train, y_train)\n",
    "                acc = get_accuracy(rdf, { \"x\" : X_test, \"y\" : y_test })\n",
    "\n",
    "                if acc > best_options[\"val\"] :\n",
    "                    best_options[\"val\"] = acc\n",
    "                    best_options[\"ests\"] = es\n",
    "                    best_options[\"crit\"] = cr\n",
    "                    best_options[\"depth\"] = dp\n",
    "\n",
    "                print(\"ACC: \",acc, \" Estimators: \",es, \" Criterion: \",cr, \" Depth: \", dp)\n",
    "    return best_options\n",
    "\n",
    "def create_rdf(features, path):\n",
    "    df = pd.read_csv(str(path))\n",
    "    #best_options = best_rdf_crit(features, df)\n",
    "    best_options = { \"val\" :  0.7354724934405781,  \"ests\" : 166,  \"crit\" : \"gini\", \"depth\" :  10 }\n",
    "\n",
    "    rdf = RandomForestClassifier(n_estimators=best_options['ests'], max_depth=best_options['depth'],                                    criterion=best_options['crit'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], \n",
    "                                            test_size=0.2, random_state=1)\n",
    "\n",
    "    rdf.fit(X_train, y_train)\n",
    "    acc = get_accuracy(rdf, { \"x\" : X_test, \"y\" : y_test })\n",
    "\n",
    "    best_options['val']=acc\n",
    "\n",
    "    print(best_options)\n",
    "    print_features(rdf)\n",
    "\n",
    "create_rdf(features, data_new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'val': 0.8342123366200412, 'ests': 166, 'crit': 'gini', 'depth': 10}\n                  importance\nduration_ms         0.125359\ninstrumentalness    0.100613\ndanceability        0.094266\nacousticness        0.090097\ntempo               0.086893\nenergy              0.084578\nloudness            0.083023\nspeechiness         0.082396\nliveness            0.077497\nvalence             0.076002\nartists             0.075350\nexplicit            0.012635\nmode                0.011294\n"
     ]
    }
   ],
   "source": [
    "data_10s_path = \"../data/decades_new/data_from_10s.csv\"\n",
    "create_rdf(features, data_10s_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}